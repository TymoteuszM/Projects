{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "gender_data = pd.read_csv(\"gender_submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Cabin_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass       Name     Sex   Age  SibSp  Parch  \\\n",
       "0            1         0       3     Braund    male  22.0      1      0   \n",
       "1            2         1       1    Cumings  female  38.0      1      0   \n",
       "2            3         1       3  Heikkinen  female  26.0      0      0   \n",
       "3            4         1       1   Futrelle  female  35.0      1      0   \n",
       "4            5         0       3      Allen    male  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin Embarked Cabin_type  \n",
       "0         A/5 21171   7.2500     0        S          0  \n",
       "1          PC 17599  71.2833   C85        C          C  \n",
       "2  STON/O2. 3101282   7.9250     0        S          0  \n",
       "3            113803  53.1000  C123        S          C  \n",
       "4            373450   8.0500     0        S          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data2 = train_data\n",
    "train_data2[\"Name\"] = train_data2[\"Name\"].str.split(pat = \",\")\n",
    "train_data2[\"Name\"] = train_data2[\"Name\"].apply(lambda x: x[0])\n",
    "#transformacja kabiny\n",
    "train_data2[\"Cabin\"] = train_data2[\"Cabin\"].fillna(\"0\")\n",
    "train_data2[\"Cabin_type\"] = train_data2[\"Cabin\"].apply(lambda x: x[0])\n",
    "train_data2[\"SibSp\"].value_counts()\n",
    "train_data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352\n",
      "667\n",
      "875\n",
      "144\n",
      "0.6666666666666666\n",
      "Andersson    False\n",
      "Sage         False\n",
      "Johnson      False\n",
      "Goodwin      False\n",
      "Carter       False\n",
      "             ...  \n",
      "Jermyn        True\n",
      "O'Connell     True\n",
      "Ayoub         True\n",
      "Coxon         True\n",
      "Patchett      True\n",
      "Name: Name, Length: 667, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "test_data[\"Name\"] = test_data[\"Name\"].str.split(pat = \",\")\n",
    "test_data[\"Name\"] = test_data[\"Name\"].apply(lambda x: x[0])\n",
    "\n",
    "list1=test_data[\"Name\"].to_list()\n",
    "list2=train_data2[\"Name\"].to_list()\n",
    "\n",
    "list3=list1+list2\n",
    "\n",
    "\n",
    "\n",
    "print(len(list(set(list1))))\n",
    "print(len(list(set(list2))))\n",
    "print(len(list(set(list3))))\n",
    "print(len(list(set(list1)))+len(list(set(list2)))-len(list(set(list3))))\n",
    "\n",
    "\n",
    "\n",
    "print(train_data2[train_data2[\"Name\"]==\"Carter\"][\"Survived\"].mean())\n",
    "print(train_data2[\"Name\"].value_counts()<2)\n",
    "#print(test_data[\"Name\"].value_counts())\n",
    "#print(test_data.info())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zamiana wieku na 1 dorosli, 0 dzieci oraz plci na 1 mezczyzni 0 kobiety\n",
    "train_data2[\"adult\"] = (train_data2[\"Age\"] > 18).astype(int)\n",
    "train_data2[\"Sex\"] = (train_data2[\"Sex\"] == \"male\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Survived  Pclass  Sex   Age     Fare  adult  Q  S  A  B  C  D  E  F  G  T\n",
      "0           0       3    1  22.0   7.2500      1  0  1  0  0  0  0  0  0  0  0\n",
      "1           1       1    0  38.0  71.2833      1  0  0  0  0  1  0  0  0  0  0\n",
      "2           1       3    0  26.0   7.9250      1  0  1  0  0  0  0  0  0  0  0\n",
      "3           1       1    0  35.0  53.1000      1  0  1  0  0  1  0  0  0  0  0\n",
      "4           0       3    1  35.0   8.0500      1  0  1  0  0  0  0  0  0  0  0\n",
      "..        ...     ...  ...   ...      ...    ... .. .. .. .. .. .. .. .. .. ..\n",
      "886         0       2    1  27.0  13.0000      1  0  1  0  0  0  0  0  0  0  0\n",
      "887         1       1    0  19.0  30.0000      1  0  1  0  1  0  0  0  0  0  0\n",
      "888         0       3    0   NaN  23.4500      0  0  1  0  0  0  0  0  0  0  0\n",
      "889         1       1    1  26.0  30.0000      1  0  0  0  0  1  0  0  0  0  0\n",
      "890         0       3    1  32.0   7.7500      1  1  0  0  0  0  0  0  0  0  0\n",
      "\n",
      "[891 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "# Rozbijamy embarked na 1 0 encoding oraz cabin\n",
    "\n",
    "df1 = pd.get_dummies(train_data2[\"Embarked\"], drop_first = True)\n",
    "df2 = pd.get_dummies(train_data2[\"Cabin_type\"], drop_first = True)\n",
    "train_data2 = train_data2.drop([\"PassengerId\", \"Name\", \"SibSp\", \"Parch\", \"Cabin\",  \"Ticket\",\"Cabin_type\",\"Embarked\"], axis = 1)\n",
    "train_data2 = pd.concat([train_data2, df1,df2], axis = 1)\n",
    "print(train_data2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass  Sex       Age      Fare  adult    Q    S    A    B    C  \\\n",
      "0       0.0     1.0  1.0  0.271174  0.014151    1.0  0.0  1.0  0.0  0.0  0.0   \n",
      "1       1.0     0.0  0.0  0.472229  0.139136    1.0  0.0  0.0  0.0  0.0  1.0   \n",
      "2       1.0     1.0  0.0  0.321438  0.015469    1.0  0.0  1.0  0.0  0.0  0.0   \n",
      "3       1.0     0.0  0.0  0.434531  0.103644    1.0  0.0  1.0  0.0  0.0  1.0   \n",
      "4       0.0     1.0  1.0  0.434531  0.015713    1.0  0.0  1.0  0.0  0.0  0.0   \n",
      "\n",
      "     D    E    F    G    T  \n",
      "0  0.0  0.0  0.0  0.0  0.0  \n",
      "1  0.0  0.0  0.0  0.0  0.0  \n",
      "2  0.0  0.0  0.0  0.0  0.0  \n",
      "3  0.0  0.0  0.0  0.0  0.0  \n",
      "4  0.0  0.0  0.0  0.0  0.0  \n"
     ]
    }
   ],
   "source": [
    "#skalowanie wartosci zeby przyjmowaly od 0 do 1 \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "train_data2 = pd.DataFrame(scaler.fit_transform(train_data2), columns = train_data2.columns)\n",
    "print(train_data2.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uzupelnienie wartosci przy pomocy k najblizszych sasiadow\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors = 5)\n",
    "train_data_filled = pd.DataFrame(imputer.fit_transform(train_data2), columns = train_data2.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usuniecie kolumn niepotrzebnych do regresji logistycznej\n",
    "train_data_filled = train_data_filled.drop([\"Survived\"], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.model_selection import train_test_split\\nxtrain,xtest,ytrain,ytest=train_test_split(train_data_filled,train_data4[\"Survived\"],test_size=0.2,random_state=2)\\nfrom sklearn.linear_model import LogisticRegression\\nlog_reg=LogisticRegression()\\nlog_reg.fit(xtrain,ytrain)\\n\\npredictions=log_reg.predict(xtest)\\nfrom sklearn.metrics import confusion_matrix\\ncm=confusion_matrix(ytest,predictions)\\nprint (cm)\\nfrom sklearn.metrics import accuracy_score\\nprint(accuracy_score(ytest,predictions))\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(train_data_filled,train_data4[\"Survived\"],test_size=0.2,random_state=2)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg=LogisticRegression()\n",
    "log_reg.fit(xtrain,ytrain)\n",
    "\n",
    "predictions=log_reg.predict(xtest)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(ytest,predictions)\n",
    "print (cm)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(ytest,predictions))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[187  22]\n",
      " [ 46 102]]\n",
      "0.8095238095238095\n"
     ]
    }
   ],
   "source": [
    "# regresja logistyczna do wyznaczenia prawidłowości modelu dla danych bez sipsp i parch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(train_data_filled,train_data2[\"Survived\"],test_size=0.4,random_state=2)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg=LogisticRegression()\n",
    "log_reg.fit(xtrain,ytrain)\n",
    "\n",
    "predictions=log_reg.predict(xtest)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(ytest,predictions)\n",
    "print (cm)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(ytest,predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass  Sex       Age      Fare  adult    Q    S    A    B    C    D    E  \\\n",
      "0     1.0  1.0  0.271174  0.014151    1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1     0.0  0.0  0.472229  0.139136    1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
      "2     1.0  0.0  0.321438  0.015469    1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
      "3     0.0  0.0  0.434531  0.103644    1.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0   \n",
      "4     1.0  1.0  0.434531  0.015713    1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "     F    G    T  \n",
      "0  0.0  0.0  0.0  \n",
      "1  0.0  0.0  0.0  \n",
      "2  0.0  0.0  0.0  \n",
      "3  0.0  0.0  0.0  \n",
      "4  0.0  0.0  0.0  \n",
      "[[-1.79427765e+00 -2.46694888e+00 -1.98401788e+00 -8.92414283e-02\n",
      "   1.31881748e-01 -4.26797623e-01 -6.10526205e-01  3.98026034e-01\n",
      "   4.10681023e-01  1.57976882e-03  4.50078907e-01  8.14252318e-01\n",
      "   1.64858702e-01  0.00000000e+00 -2.13119405e-01]] [2.97518926]\n"
     ]
    }
   ],
   "source": [
    "#wspolczynniki w regresji logistycznej\n",
    "print(train_data_filled.head())\n",
    "print(log_reg.coef_ ,log_reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1.\n",
      " 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1.]\n",
      "0.7821229050279329\n"
     ]
    }
   ],
   "source": [
    "# metoda k najblizszych sasiadow do wyznaczenia prawidlowosci modelu\n",
    "\n",
    "\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(train_data_filled,train_data2[\"Survived\"],test_size=0.2,random_state=2)\n",
    "X = xtrain\n",
    "y = ytrain\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X, y)\n",
    "\n",
    "ypredict=neigh.predict(xtest)\n",
    "print(ypredict)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(ytest,ypredict))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nall_passengers = pd.concat([train_data.drop(\"Survived\", axis = 1), test_data], axis = 0)\\nall_passengers = all_passengers.reset_index(drop = True)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "all_passengers = pd.concat([train_data.drop(\"Survived\", axis = 1), test_data], axis = 0)\n",
    "all_passengers = all_passengers.reset_index(drop = True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_data.drop(\"Survived\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nall_passengers[\"Name\"] = all_passengers[\"Name\"].str.split(pat = \",\")\\nall_passengers[\"Name\"] = all_passengers[\"Name\"].apply(lambda x: x[0])\\nall_passengers[\"Name\"].value_counts().head(20)\\ntrav_together = all_passengers[(all_passengers[\"SibSp\"] != 0) | (all_passengers[\"Parch\"] != 0)].sort_values(\"Name\")\\ntrav_together[\"Name\"].value_counts().head(30)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "all_passengers[\"Name\"] = all_passengers[\"Name\"].str.split(pat = \",\")\n",
    "all_passengers[\"Name\"] = all_passengers[\"Name\"].apply(lambda x: x[0])\n",
    "all_passengers[\"Name\"].value_counts().head(20)\n",
    "trav_together = all_passengers[(all_passengers[\"SibSp\"] != 0) | (all_passengers[\"Parch\"] != 0)].sort_values(\"Name\")\n",
    "trav_together[\"Name\"].value_counts().head(30)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zamiana wieku na 1 dorosli, 0 dzieci oraz plci na 1 mezczyzni 0 kobiety\n",
    "test_data[\"adult\"] = (test_data[\"Age\"] > 18).astype(int)\n",
    "test_data[\"Sex\"] = (test_data[\"Sex\"] == \"male\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass  Sex   Age      Fare  adult  Q  S  A  B  C  D  E  F  G\n",
      "0         3    1  34.5    7.8292      1  1  0  0  0  0  0  0  0  0\n",
      "1         3    0  47.0    7.0000      1  0  1  0  0  0  0  0  0  0\n",
      "2         2    1  62.0    9.6875      1  1  0  0  0  0  0  0  0  0\n",
      "3         3    1  27.0    8.6625      1  0  1  0  0  0  0  0  0  0\n",
      "4         3    0  22.0   12.2875      1  0  1  0  0  0  0  0  0  0\n",
      "..      ...  ...   ...       ...    ... .. .. .. .. .. .. .. .. ..\n",
      "413       3    1   NaN    8.0500      0  0  1  0  0  0  0  0  0  0\n",
      "414       1    0  39.0  108.9000      1  0  0  0  0  1  0  0  0  0\n",
      "415       3    1  38.5    7.2500      1  0  1  0  0  0  0  0  0  0\n",
      "416       3    1   NaN    8.0500      0  0  1  0  0  0  0  0  0  0\n",
      "417       3    1   NaN   22.3583      0  0  0  0  0  0  0  0  0  0\n",
      "\n",
      "[418 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "test_data2=test_data\n",
    "test_data2[\"Cabin\"] = test_data[\"Cabin\"].fillna(\"0\")\n",
    "test_data2[\"Cabin_type\"] = test_data2[\"Cabin\"].apply(lambda x: x[0])\n",
    "\n",
    "df1 = pd.get_dummies(test_data2[\"Embarked\"], drop_first = True)\n",
    "df2 = pd.get_dummies(test_data2[\"Cabin_type\"], drop_first = True)\n",
    "test_data2 = test_data2.drop([\"PassengerId\", \"Name\", \"SibSp\", \"Parch\",  \"Ticket\",\"Cabin_type\",\"Embarked\",\"Cabin\"], axis = 1)\n",
    "test_data2 = pd.concat([test_data2, df1,df2], axis = 1)\n",
    "print(test_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass  Sex       Age      Fare  adult    Q    S    A    B    C    D    E  \\\n",
      "0     1.0  1.0  0.452723  0.015282    1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1     1.0  0.0  0.617566  0.013663    1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
      "2     0.5  1.0  0.815377  0.018909    1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "3     1.0  1.0  0.353818  0.016908    1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
      "4     1.0  0.0  0.287881  0.023984    1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "     F    G  \n",
      "0  0.0  0.0  \n",
      "1  0.0  0.0  \n",
      "2  0.0  0.0  \n",
      "3  0.0  0.0  \n",
      "4  0.0  0.0  \n"
     ]
    }
   ],
   "source": [
    "#skalowanie wartosci zeby przyjmowaly od 0 do 1 \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "test_data2 = pd.DataFrame(scaler.fit_transform(test_data2), columns = test_data2.columns)\n",
    "print(test_data2.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 14 columns):\n",
      "Pclass    418 non-null float64\n",
      "Sex       418 non-null float64\n",
      "Age       418 non-null float64\n",
      "Fare      418 non-null float64\n",
      "adult     418 non-null float64\n",
      "Q         418 non-null float64\n",
      "S         418 non-null float64\n",
      "A         418 non-null float64\n",
      "B         418 non-null float64\n",
      "C         418 non-null float64\n",
      "D         418 non-null float64\n",
      "E         418 non-null float64\n",
      "F         418 non-null float64\n",
      "G         418 non-null float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 45.8 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors = 5)\n",
    "test_data_filled = pd.DataFrame(imputer.fit_transform(test_data2), columns = test_data2.columns)\n",
    "print(test_data_filled.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Pclass', 'Sex', 'Age', 'Fare', 'adult', 'Q', 'S', 'A', 'B', 'C', 'D',\n",
      "       'E', 'F', 'G', 'T'],\n",
      "      dtype='object')\n",
      "Index(['Pclass', 'Sex', 'Age', 'Fare', 'adult', 'Q', 'S', 'A', 'B', 'C', 'D',\n",
      "       'E', 'F', 'G', 'T'],\n",
      "      dtype='object')\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0.\n",
      " 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0.\n",
      " 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1.\n",
      " 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0.\n",
      " 0. 1. 0. 1. 0. 0. 1. 0. 0. 1.]\n",
      "0.80622009569378\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xtrain=train_data_filled\n",
    "xtest=test_data_filled\n",
    "xtest[\"T\"]=0\n",
    "ytrain=train_data2[\"Survived\"]\n",
    "ytest=gender_data[\"Survived\"]\n",
    "print(xtrain.columns)\n",
    "print(xtest.columns)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X, y)\n",
    "\n",
    "ypredict=neigh.predict(xtest)\n",
    "print(ypredict)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(ytest,ypredict))\n",
    "\n",
    "\n",
    "d={'PassengerId':test_data[\"PassengerId\"],'Survived' :(ypredict.astype(int))}\n",
    "data_submission=pd.DataFrame(data=d)\n",
    "\n",
    "data_submission.to_csv(r'data_submission_knn2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[251  15]\n",
      " [  6 146]]\n",
      "0.9497607655502392\n"
     ]
    }
   ],
   "source": [
    "#Regresja logistyczna dla danych uzupelnionych z sipsp i parch\n",
    "\n",
    "xtrain=train_data_filled\n",
    "xtest=test_data_filled\n",
    "ytrain=train_data2[\"Survived\"]\n",
    "ytest=gender_data[\"Survived\"]\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg=LogisticRegression()\n",
    "log_reg.fit(xtrain,ytrain)\n",
    "\n",
    "predictions=log_reg.predict(xtest)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(ytest,predictions)\n",
    "print (cm)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(ytest,predictions))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "e={'PassengerId':test_data[\"PassengerId\"],'Survived' :(predictions.astype(int))}\n",
    "data_submission=pd.DataFrame(data=e)\n",
    "data_submission.to_csv(r'data_submission_regression2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eta': 0.15, 'max_depth': 4, 'subsample': 0.7, 'use_label_encoder': False} 0.8575167911618855\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters= {\n",
    "    'use_label_encoder':[False],\n",
    "    'eta': [0.05,0.1,0.11,0.12,0.14,0.15,0.16,0.17],\n",
    "    'max_depth':[3,4,5,6,],\n",
    "    'subsample':[0.6,0.65,0.67,0.7,0.72,0.75,0.8,]    \n",
    "}\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf=XGBClassifier()\n",
    "\n",
    "clf = GridSearchCV(clf, parameters)\n",
    "clf.fit(xtrain ,ytrain)\n",
    "\n",
    "#sorted(clf.cv_results_.keys())\n",
    "\n",
    "print(clf.best_params_,clf.best_score_)\n",
    "\n",
    "#clf2=LogisticRegression()\n",
    "#clf3=KNeighborsClassifier(n_neighbors=3)\n",
    "    #scores=cross_val_score(clf,xtrain,ytrain,cv=10)\n",
    "#scores2=cross_val_score(clf2,xtrain,ytrain,cv=10)\n",
    "#scores3=cross_val_score(clf3,xtrain,ytrain,cv=10)\n",
    "    #print(f'XGBClassifier wynik to {scores.mean()}')\n",
    "#print(f'Logictic Regression wynik to {scores2.mean()}')\n",
    "#print(f'KNN Neighbours wynik to {scores3.mean()}')\n",
    "\n",
    "#clf_sub=XGBClassifier(use_label_encoder=False,eta=0.15,max_depth=4,subsample=1)\n",
    "#clf_sub.fit(xtrain,ytrain)\n",
    "\n",
    "#predictions=clf_sub.predict(xtest)\n",
    "\n",
    "#e={'PassengerId':test_data[\"PassengerId\"],'Survived' :(predictions.astype(int))}\n",
    "#data_submission=pd.DataFrame(data=e)\n",
    "#data_submission.to_csv(r'data_submission_xgboost2.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eta': 0.15, 'use_label_encoder': False} 0.8406816897872073\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(clf.best_params_,clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2=XGBClassifier(use_label_encoder=False,eta=0.15,subsample=0.7,max_depth=4)\n",
    "clf2.fit(xtrain,ytrain)\n",
    "\n",
    "predictions=clf2.predict(xtest)\n",
    "\n",
    "e={'PassengerId':test_data[\"PassengerId\"],'Survived' :(predictions.astype(int))}\n",
    "data_submission=pd.DataFrame(data=e)\n",
    "data_submission.to_csv(r'data_submission_xgboost3.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
